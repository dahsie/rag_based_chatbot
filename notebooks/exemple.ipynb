{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "sys.path.append(\"/home/dah/llama/chatbot/rag_based_chatbot/src\")\n",
    "from vectorstore import VectorStore\n",
    "from workflow_handler import WorkflowHandler\n",
    "from document_grader import GradeDocuments\n",
    "from question_rewriter_output import QuestionRewriter\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain import hub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = VectorStore()\n",
    "vect.create_vectorsore(urls = urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm_grader = JsonOutputParser(pydantic_object=GradeDocuments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document, to a user question: {question}\\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. Here is the retrieved document : {document}\\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question following this format_instructions :{format_instructions}.\n",
    "    The response must only be 'yes' or 'no', never and never explain the response.\"\"\"\n",
    "\n",
    "grade_prompt = PromptTemplate(\n",
    "    template=system,\n",
    "    input_variales = ['document', 'question'],\n",
    "    partial_variables={\"format_instructions\": structured_llm_grader.get_format_instructions()},\n",
    ")\n",
    "retrieval_grader = (grade_prompt | llm )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewriter = JsonOutputParser(pydantic_object=QuestionRewriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\n",
    "     The output must be a JSON with the following key 'question' without any explaination\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter = (re_write_prompt | llm | rewriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dah/miniconda3/envs/chatbot/lib/python3.12/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool = DuckDuckGoSearchResults(output_format=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfh = WorkflowHandler(vectorstore=vect, rag_chain= rag_chain, grader_parser= structured_llm_grader,\n",
    "                      retrieval_grader=retrieval_grader,question_rewriter=question_rewriter,web_search_tool= web_search_tool)\n",
    "wfh.build_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node 'retrieve' :\"\n",
      "'\\n---\\n'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      " score : {\n",
      "\"score\": \"no\"\n",
      "}\n",
      "grade : no\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      " score : {\"score\": \"no\"}\n",
      "grade : no\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      " score : Based on the provided schema and question, the document is relevant and I would score it as 'yes'. The document discusses the processing of user input in AlphaCodium, which aligns with the question asking about how the AlphaCodium paper works.\n",
      "grade : no\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      " score : { \"score\": \"no\" }\n",
      "grade : no\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "\"Node 'grade_documents' :\"\n",
      "'\\n---\\n'\n",
      "---TRANSFORM QUERY---\n",
      "\"Node 'transform_query' :\"\n",
      "'\\n---\\n'\n",
      "---WEB SEARCH---\n",
      " question : What is the explanation of how the AlphaCodium paper functions?\n",
      "\"Node 'web_search_node' :\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "\"Node 'generate' :\"\n",
      "'\\n---\\n'\n",
      "(' In this paper, the authors introduce AlphaCodium, an approach to improve '\n",
      " 'code generation by large language models using a test-based, multi-stage '\n",
      " 'iterative flow. AlphaCodium achieves similar accuracy as other methods but '\n",
      " 'uses significantly fewer LLM calls, making it more efficient. For instance, '\n",
      " 'on CodeContests, AlphaCodium outperforms CodeChain with the same model and '\n",
      " 'metric.')\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"How does the AlphaCodium paper work?\"}\n",
    "wfh.invoke(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
